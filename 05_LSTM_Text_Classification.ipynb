{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05-LSTM - Text Classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPjsN2Sl8Tbs84ptveb+N5T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/epigos/learning-pytorch/blob/master/05_LSTM_Text_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgFVThBCX0ed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict, deque\n",
        "import math\n",
        "import time\n",
        "import copy\n",
        "import itertools\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torchtext import data \n",
        "import torchtext\n",
        "from torchtext import datasets\n",
        "from torchtext.vocab import GloVe\n",
        "\n",
        "import pandas as pd\n",
        "import spacy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8ID8zB_pJAT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3fed8ca0-5519-4999-ee55-3230e4ab70a7"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if torch.cuda.is_available(): print('Device name:', torch.cuda.get_device_name())"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device name: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHLiYlpFpWL5",
        "colab_type": "text"
      },
      "source": [
        "# Load IMDB dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMeZyYpOpjM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the text and label field\n",
        "# lowercase all the text, tokenize the text, and trim it to a maximum length of 200\n",
        "TEXT = data.Field(lower=True, batch_first=False, fix_length=200)\n",
        "LABEL = data.Field(sequential=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuXs8-ASpYwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load dataset\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl9sJyNUuqmU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "31c79496-be17-490b-b8fb-c5c4eb2a3e90"
      },
      "source": [
        "print(len(train_data), len(test_data))"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjNvKm26qEqO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d0e16953-e34a-4c4f-ac2f-740f6401106b"
      },
      "source": [
        "print(\"Train fields:\", train_data.fields)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train fields: {'text': <torchtext.data.field.Field object at 0x7faff4d92198>, 'label': <torchtext.data.field.Field object at 0x7faff4d92d30>}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBxSuC_pqSCL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0dcf9b6e-494c-41a5-d80a-40324518dd1f"
      },
      "source": [
        "print(vars(train_data[0]))"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['richard', 'widmark', 'is', 'a', 'tainted', 'character', 'in', 'this', 'movie.', 'he', 'is', 'a', 'professional', 'pickpocket.', \"he's\", 'been', 'in', 'prison', 'three', 'times,', 'yet', 'at', 'the', 'beginning', 'of', 'the', 'film,', 'he', 'tries', 'to', 'make', 'it', 'four.', 'thelma', 'ritter', 'is', 'a', 'busy', 'body', 'selling', 'information', 'to', 'almost', 'everybody.', 'jean', 'peters', 'is', 'amazing', 'as', 'the', 'girl', 'flamed', 'by', 'widmark.<br', '/><br', '/>this', 'is', 'a', 'period', 'piece', 'during', 'the', 'mccarthy', 'era', 'where', 'the', 'red', 'scare', 'ruled', 'the', 'politics', 'and', 'is', 'worked', 'into', 'this', 'plot', 'quite', 'nicely.', 'what', 'is', 'unusual', 'about', 'this', 'film', 'is', 'that', 'peters', '&', 'ritter', 'are', 'both', 'victims', 'of', 'violent', 'beatings', 'in', 'an', 'era', 'where', 'women', 'were', 'seldom', 'more', 'than', 'sex', 'objects', 'in', 'films.', 'this', 'is', 'what', 'makes', 'this', 'film', 'noir', 'as', 'women', 'often', 'got', 'different', 'roles', 'in', 'this', 'type', 'of', 'film.<br', '/><br', '/>the', 'film', 'is', 'only', '87', 'minutes', 'long', 'and', 'was', 'obviously', 'made', 'by', 'fox', 'as', 'the', 'under', 'card', 'for', 'double', 'features', 'in', 'the', 'theater.', 'the', 'sets', 'show', 'it', 'is', 'a', 'limited', 'budget', 'film.', 'the', 'script', 'made', 'j', 'edgar', 'hoover', 'mad', 'because', 'patriotism', 'is', 'given', 'short', 'shrift.', 'hoover', 'wanted', 'it', 'changed.<br', '/><br', '/>instead,', 'it', 'became', 'a', 'b', 'under', 'card', 'picture', 'that', 'was', 'a', 'sleeper', 'hit', 'in', '1953.', 'the', 'script', '&', 'acting', 'in', 'it', 'are', 'better', 'than', 'other', 'big', 'features', 'were', 'that', 'year.'], 'label': 'pos'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X0hSuBXr3kU",
        "colab_type": "text"
      },
      "source": [
        "## Create word vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_2a3z6HqUiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create vocabulary using GloVe with vocab size of 10000 and min word frequency of 10\n",
        "TEXT.build_vocab(train_data, vectors=GloVe(name='6B', dim=300), max_size=10000, min_freq=10)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zncYE4oNrtg5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1fa16b7a-6309-4575-fb79-b392284be0e8"
      },
      "source": [
        "# how big is our vocabulary\n",
        "(len(TEXT.vocab), len(LABEL.vocab))"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10002, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiaxJQ2ysE2Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "b4f54a20-c7e1-4d08-fe3f-07950f52ff10"
      },
      "source": [
        "# most common words\n",
        "TEXT.vocab.freqs.most_common(10)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 322198),\n",
              " ('a', 159953),\n",
              " ('and', 158572),\n",
              " ('of', 144462),\n",
              " ('to', 133967),\n",
              " ('is', 104171),\n",
              " ('in', 90527),\n",
              " ('i', 70480),\n",
              " ('this', 69714),\n",
              " ('that', 66292)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ekn-jc6GsLoN",
        "colab_type": "text"
      },
      "source": [
        "## Create data loader\n",
        "\n",
        "We use the torchtext BucketIterator function for creating batches, and the size of the batches will be sequence length and batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_0ifPZfsN69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader, test_loader = data.BucketIterator.splits(\n",
        "    (train_data, test_data), batch_size=32, device=device, repeat=False,\n",
        "    sort_key = lambda x: len(x.text), sort_within_batch = False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyD7BjLmyquf",
        "colab_type": "text"
      },
      "source": [
        "# Create the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKMTVp9VyyjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IMDBLSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, hidden_size, output_size, num_layers=2, \n",
        "                 batch_size=32):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.batch_size = batch_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embed = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=num_layers)\n",
        "        self.fcl = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=-1)\n",
        "        self.dropout = nn.Dropout(0.8)\n",
        "\n",
        "    def forward(self, seq):\n",
        "        batch_size = seq.size()[1]\n",
        "        if batch_size != self.batch_size:\n",
        "            self.batch_size = batch_size\n",
        "        # get embedding output\n",
        "        x = self.embed(seq)\n",
        "        # get initial hidden output\n",
        "        h0 = c0 = Variable(x.data.new(*(self.num_layers, self.batch_size, self.hidden_size)).zero_())\n",
        "        # get output from lstm layer\n",
        "        output, _ = self.lstm(x, (h0, c0))\n",
        "        # get output from linear layer\n",
        "        fc = self.dropout(self.fcl(output[-1]))\n",
        "        return self.softmax(fc)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ1Qrfiz0_0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test model\n",
        "vocab_size = len(TEXT.vocab)\n",
        "hidden_size = 100\n",
        "output_size = len(LABEL.vocab)\n",
        "model = IMDBLSTM(vocab_size, hidden_size, output_size).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-ctaIzP1Eql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9669e3aa-446d-4a06-b3e9-3be71dcef66e"
      },
      "source": [
        "model"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IMDBLSTM(\n",
              "  (embed): Embedding(10002, 100)\n",
              "  (lstm): LSTM(100, 100, num_layers=2)\n",
              "  (fcl): Linear(in_features=100, out_features=3, bias=True)\n",
              "  (softmax): LogSoftmax()\n",
              "  (dropout): Dropout(p=0.8, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILfP9UsW3pmo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "29090e3c-cb80-410a-cccc-4aba3cbb38bb"
      },
      "source": [
        "# input size 200 * 32\n",
        "out = model(torch.randint(0, vocab_size, (200, 32), device=device))\n",
        "out"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.0986, -1.0986, -1.0986],\n",
              "        [-1.1273, -1.0436, -1.1273],\n",
              "        [-1.1940, -1.0821, -1.0269],\n",
              "        [-1.0348, -1.0348, -1.2398],\n",
              "        [-1.2031, -1.0502, -1.0502],\n",
              "        [-1.3127, -1.0066, -1.0066],\n",
              "        [-1.0986, -1.0986, -1.0986],\n",
              "        [-1.0907, -1.1146, -1.0907],\n",
              "        [-1.0986, -1.0986, -1.0986],\n",
              "        [-1.2371, -1.0360, -1.0360],\n",
              "        [-1.0986, -1.0986, -1.0986],\n",
              "        [-1.2116, -1.0466, -1.0466],\n",
              "        [-1.1235, -1.0507, -1.1235],\n",
              "        [-1.0221, -1.0221, -1.2719],\n",
              "        [-1.2982, -1.0120, -1.0120],\n",
              "        [-1.1128, -1.0708, -1.1128],\n",
              "        [-1.0986, -1.0986, -1.0986],\n",
              "        [-1.0870, -1.1223, -1.0870],\n",
              "        [-1.0986, -1.0986, -1.0986],\n",
              "        [-1.0986, -1.0986, -1.0986],\n",
              "        [-1.0442, -1.0443, -1.2171],\n",
              "        [-1.0294, -1.0294, -1.2532],\n",
              "        [-1.0986, -1.0986, -1.0986],\n",
              "        [-1.0986, -1.0986, -1.0986],\n",
              "        [-1.0986, -1.0986, -1.0986],\n",
              "        [-1.0986, -1.0986, -1.0986],\n",
              "        [-1.1194, -0.9998, -1.1856],\n",
              "        [-1.0986, -1.0986, -1.0986],\n",
              "        [-1.3665, -0.8401, -1.1605],\n",
              "        [-1.0986, -1.0986, -1.0986],\n",
              "        [-1.0986, -1.0986, -1.0986],\n",
              "        [-1.2798, -1.0190, -1.0190]], device='cuda:0',\n",
              "       grad_fn=<LogSoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yhTQJxK_ud2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2949a2a2-24d0-4967-f6c2-be2e1633b5a1"
      },
      "source": [
        "out.size()"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0W9NC4p7Hln",
        "colab_type": "text"
      },
      "source": [
        "## Train the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehUurP3U7JNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, data_loader, epochs=5):\n",
        "    model = model.to(device)\n",
        "    # define training functions\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.NLLLoss()\n",
        "    # define training variables\n",
        "    since = time.time()\n",
        "    best_weights = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    loss_history = defaultdict(lambda: deque(maxlen=epochs))\n",
        "    accuracy_history = defaultdict(lambda: deque(maxlen=epochs))\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        print('\\nEpoch {}/{}'.format(epoch, epochs))\n",
        "        print('-' * 60)    \n",
        "        \n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            for batch in data_loader[phase]:\n",
        "                text, target = batch.text.to(device), batch.label.to(device)\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # make predictions\n",
        "                    outputs = model(text)\n",
        "                    loss = criterion(outputs, target)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                    # statistics\n",
        "                running_loss += loss.item() * text.size(0)\n",
        "                running_corrects += preds.eq(target.view_as(preds)).cpu().sum()\n",
        "                \n",
        "            data_size = len(data_loader[phase].dataset)\n",
        "            epoch_loss = running_loss / data_size\n",
        "            epoch_acc = running_corrects.double().item() / data_size\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "            loss_history[phase].append(epoch_loss)\n",
        "            accuracy_history[phase].append(epoch_acc)\n",
        "            \n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_weights = copy.deepcopy(model.state_dict())\n",
        "            \n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('-' * 60)\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:.3f} %'.format(100 * best_acc))\n",
        "    print('=' * 60, '\\n')\n",
        "    # load best weights\n",
        "    model.load_state_dict(best_weights)\n",
        "    return loss_history, accuracy_history\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMqMzzXg86XP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e3eb8409-caaf-4362-c999-d59933a52459"
      },
      "source": [
        "# define data loader\n",
        "data_loader = {'train': train_loader, 'val': test_loader}\n",
        "# instantiate model\n",
        "model = IMDBLSTM(vocab_size, hidden_size, output_size)\n",
        "# train model\n",
        "loss_history, accuracy_history = train(model, data_loader, epochs=25)"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/25\n",
            "------------------------------------------------------------\n",
            "train Loss: 6.2792 Acc: 0.2450\n",
            "val Loss: 5.0806 Acc: 0.5093\n",
            "\n",
            "Epoch 2/25\n",
            "------------------------------------------------------------\n",
            "train Loss: 6.2629 Acc: 0.2444\n",
            "val Loss: 4.9133 Acc: 0.5255\n",
            "\n",
            "Epoch 3/25\n",
            "------------------------------------------------------------\n",
            "train Loss: 6.2245 Acc: 0.2422\n",
            "val Loss: 4.8287 Acc: 0.5540\n",
            "\n",
            "Epoch 4/25\n",
            "------------------------------------------------------------\n",
            "train Loss: 6.1424 Acc: 0.2428\n",
            "val Loss: 4.7686 Acc: 0.5942\n",
            "\n",
            "Epoch 5/25\n",
            "------------------------------------------------------------\n",
            "train Loss: 6.1680 Acc: 0.2414\n",
            "val Loss: 4.7011 Acc: 0.5593\n",
            "\n",
            "Epoch 6/25\n",
            "------------------------------------------------------------\n",
            "train Loss: 5.9822 Acc: 0.2511\n",
            "val Loss: 3.9085 Acc: 0.7623\n",
            "\n",
            "Epoch 7/25\n",
            "------------------------------------------------------------\n",
            "train Loss: 5.7062 Acc: 0.2575\n",
            "val Loss: 3.7242 Acc: 0.7761\n",
            "\n",
            "Epoch 8/25\n",
            "------------------------------------------------------------\n",
            "train Loss: 5.5367 Acc: 0.2659\n",
            "val Loss: 3.0831 Acc: 0.8118\n",
            "\n",
            "Epoch 9/25\n",
            "------------------------------------------------------------\n",
            "train Loss: 5.4149 Acc: 0.2709\n",
            "val Loss: 3.3050 Acc: 0.8233\n",
            "\n",
            "Epoch 10/25\n",
            "------------------------------------------------------------\n",
            "train Loss: 5.3452 Acc: 0.2687\n",
            "val Loss: 3.1276 Acc: 0.8258\n",
            "\n",
            "Epoch 11/25\n",
            "------------------------------------------------------------\n",
            "train Loss: 5.2369 Acc: 0.2763\n",
            "val Loss: 3.0079 Acc: 0.8293\n",
            "\n",
            "Epoch 12/25\n",
            "------------------------------------------------------------\n",
            "train Loss: 5.1816 Acc: 0.2772\n",
            "val Loss: 2.9922 Acc: 0.8252\n",
            "\n",
            "Epoch 13/25\n",
            "------------------------------------------------------------\n",
            "train Loss: 5.1266 Acc: 0.2818\n",
            "val Loss: 2.8248 Acc: 0.8234\n",
            "\n",
            "Epoch 14/25\n",
            "------------------------------------------------------------\n",
            "train Loss: 5.0809 Acc: 0.2827\n",
            "val Loss: 2.7769 Acc: 0.8304\n",
            "\n",
            "Epoch 15/25\n",
            "------------------------------------------------------------\n",
            "train Loss: 5.0272 Acc: 0.2819\n",
            "val Loss: 2.7291 Acc: 0.8329\n",
            "\n",
            "Epoch 16/25\n",
            "------------------------------------------------------------\n",
            "train Loss: 4.9299 Acc: 0.2925\n",
            "val Loss: 2.7165 Acc: 0.8322\n",
            "\n",
            "Epoch 17/25\n",
            "------------------------------------------------------------\n",
            "train Loss: 4.9033 Acc: 0.2918\n",
            "val Loss: 2.6857 Acc: 0.8283\n",
            "\n",
            "Epoch 18/25\n",
            "------------------------------------------------------------\n",
            "train Loss: 4.8726 Acc: 0.2887\n",
            "val Loss: 2.5613 Acc: 0.8346\n",
            "\n",
            "Epoch 19/25\n",
            "------------------------------------------------------------\n",
            "train Loss: 4.8754 Acc: 0.2883\n",
            "val Loss: 2.6215 Acc: 0.8281\n",
            "\n",
            "Epoch 20/25\n",
            "------------------------------------------------------------\n",
            "train Loss: 4.8472 Acc: 0.2911\n",
            "val Loss: 2.6377 Acc: 0.8285\n",
            "\n",
            "Epoch 21/25\n",
            "------------------------------------------------------------\n",
            "train Loss: 4.7789 Acc: 0.2953\n",
            "val Loss: 2.5633 Acc: 0.8322\n",
            "\n",
            "Epoch 22/25\n",
            "------------------------------------------------------------\n",
            "train Loss: 4.7628 Acc: 0.2940\n",
            "val Loss: 2.6009 Acc: 0.8252\n",
            "\n",
            "Epoch 23/25\n",
            "------------------------------------------------------------\n",
            "train Loss: 4.7412 Acc: 0.2966\n",
            "val Loss: 2.5752 Acc: 0.8304\n",
            "\n",
            "Epoch 24/25\n",
            "------------------------------------------------------------\n",
            "train Loss: 4.7568 Acc: 0.2902\n",
            "val Loss: 2.6013 Acc: 0.8310\n",
            "\n",
            "Epoch 25/25\n",
            "------------------------------------------------------------\n",
            "train Loss: 4.7377 Acc: 0.2931\n",
            "val Loss: 2.6350 Acc: 0.8335\n",
            "------------------------------------------------------------\n",
            "Training complete in 7m 23s\n",
            "Best val Acc: 83.456 %\n",
            "============================================================ \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktssZ5nn9GWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}